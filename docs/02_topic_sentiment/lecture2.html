<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lecture 2 â€“ NLP Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">NLP Notes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-topic--sentiment" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Topic &amp; Sentiment</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-topic--sentiment">    
        <li>
    <a class="dropdown-item" href="../02_topic_sentiment/lecture2.html">
 <span class="dropdown-text">Language Models &amp; Sentiment Notes</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#language-modeling-and-probability-foundations" id="toc-language-modeling-and-probability-foundations" class="nav-link active" data-scroll-target="#language-modeling-and-probability-foundations">Language Modeling and Probability Foundations</a>
  <ul class="collapse">
  <li><a href="#sequence-modeling-and-prediction" id="toc-sequence-modeling-and-prediction" class="nav-link" data-scroll-target="#sequence-modeling-and-prediction">Sequence Modeling and Prediction</a></li>
  <li><a href="#chain-rule-of-probability" id="toc-chain-rule-of-probability" class="nav-link" data-scroll-target="#chain-rule-of-probability">Chain Rule of Probability</a></li>
  </ul></li>
  <li><a href="#perplexity-and-cross-entropy" id="toc-perplexity-and-cross-entropy" class="nav-link" data-scroll-target="#perplexity-and-cross-entropy">Perplexity and Cross-Entropy</a>
  <ul class="collapse">
  <li><a href="#perplexity" id="toc-perplexity" class="nav-link" data-scroll-target="#perplexity">Perplexity</a></li>
  <li><a href="#cross-entropy" id="toc-cross-entropy" class="nav-link" data-scroll-target="#cross-entropy">Cross-Entropy</a></li>
  <li><a href="#kl-divergence-relative-entropy" id="toc-kl-divergence-relative-entropy" class="nav-link" data-scroll-target="#kl-divergence-relative-entropy">KL Divergence (Relative Entropy)</a></li>
  </ul></li>
  <li><a href="#text-representation-models" id="toc-text-representation-models" class="nav-link" data-scroll-target="#text-representation-models">Text Representation Models</a>
  <ul class="collapse">
  <li><a href="#bag-of-words-bow" id="toc-bag-of-words-bow" class="nav-link" data-scroll-target="#bag-of-words-bow">Bag-of-Words (BoW)</a></li>
  <li><a href="#limitations-of-bow" id="toc-limitations-of-bow" class="nav-link" data-scroll-target="#limitations-of-bow">Limitations of BoW</a></li>
  <li><a href="#tf-idf-term-frequency-inverse-document-frequency" id="toc-tf-idf-term-frequency-inverse-document-frequency" class="nav-link" data-scroll-target="#tf-idf-term-frequency-inverse-document-frequency">TF-IDF (Term Frequency-Inverse Document Frequency)</a></li>
  <li><a href="#normalized-term-frequency" id="toc-normalized-term-frequency" class="nav-link" data-scroll-target="#normalized-term-frequency">Normalized Term Frequency</a></li>
  </ul></li>
  <li><a href="#n-gram-models" id="toc-n-gram-models" class="nav-link" data-scroll-target="#n-gram-models">N-gram Models</a>
  <ul class="collapse">
  <li><a href="#bi-grams-and-n-grams" id="toc-bi-grams-and-n-grams" class="nav-link" data-scroll-target="#bi-grams-and-n-grams">Bi-grams and N-grams</a></li>
  <li><a href="#n-gram-ä¸€èˆ¬åŒ–" id="toc-n-gram-ä¸€èˆ¬åŒ–" class="nav-link" data-scroll-target="#n-gram-ä¸€èˆ¬åŒ–">N-gram ä¸€èˆ¬åŒ–</a></li>
  <li><a href="#out-of-vocabulary-wordsè¯è¡¨å¤–è¯" id="toc-out-of-vocabulary-wordsè¯è¡¨å¤–è¯" class="nav-link" data-scroll-target="#out-of-vocabulary-wordsè¯è¡¨å¤–è¯">Out-of-Vocabulary Wordsï¼ˆè¯è¡¨å¤–è¯ï¼‰</a></li>
  </ul></li>
  <li><a href="#sentiment-analysis-and-semantic-orientation" id="toc-sentiment-analysis-and-semantic-orientation" class="nav-link" data-scroll-target="#sentiment-analysis-and-semantic-orientation">Sentiment Analysis and Semantic Orientation</a>
  <ul class="collapse">
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition">Definition</a></li>
  <li><a href="#lexicon-based-approach" id="toc-lexicon-based-approach" class="nav-link" data-scroll-target="#lexicon-based-approach">Lexicon-Based Approach</a></li>
  <li><a href="#wordnet-role" id="toc-wordnet-role" class="nav-link" data-scroll-target="#wordnet-role">WordNet Role</a></li>
  <li><a href="#limitations-of-lexicon-methods" id="toc-limitations-of-lexicon-methods" class="nav-link" data-scroll-target="#limitations-of-lexicon-methods">Limitations of Lexicon Methods</a></li>
  </ul></li>
  <li><a href="#summary-table" id="toc-summary-table" class="nav-link" data-scroll-target="#summary-table">Summary Table</a></li>
  <li><a href="#what-are-topic-models" id="toc-what-are-topic-models" class="nav-link" data-scroll-target="#what-are-topic-models">What Are Topic Models?</a></li>
  <li><a href="#lda-graphical-structure-plate-notation" id="toc-lda-graphical-structure-plate-notation" class="nav-link" data-scroll-target="#lda-graphical-structure-plate-notation">LDA Graphical Structure &amp; Plate Notation</a></li>
  <li><a href="#lda-as-soft-clustering" id="toc-lda-as-soft-clustering" class="nav-link" data-scroll-target="#lda-as-soft-clustering">LDA as Soft Clustering</a></li>
  <li><a href="#lda-as-dimension-reduction" id="toc-lda-as-dimension-reduction" class="nav-link" data-scroll-target="#lda-as-dimension-reduction">LDA as Dimension Reduction</a></li>
  <li><a href="#variational-inference-in-lda" id="toc-variational-inference-in-lda" class="nav-link" data-scroll-target="#variational-inference-in-lda">Variational Inference in LDA</a></li>
  <li><a href="#extensions-of-lda" id="toc-extensions-of-lda" class="nav-link" data-scroll-target="#extensions-of-lda">Extensions of LDA</a></li>
  <li><a href="#sentence-constrained-lda" id="toc-sentence-constrained-lda" class="nav-link" data-scroll-target="#sentence-constrained-lda">Sentence-Constrained LDA</a>
  <ul class="collapse">
  <li><a href="#æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜" id="toc-æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜" class="nav-link" data-scroll-target="#æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜">æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜ï¼š</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 2</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<hr>
<section id="language-modeling-and-probability-foundations" class="level2">
<h2 class="anchored" data-anchor-id="language-modeling-and-probability-foundations">Language Modeling and Probability Foundations</h2>
<section id="sequence-modeling-and-prediction" class="level3">
<h3 class="anchored" data-anchor-id="sequence-modeling-and-prediction">Sequence Modeling and Prediction</h3>
<p>Language models predict the next word in a sequence given the preceding words. This is typically modeled using conditional probability:</p>
<p>è¯­è¨€æ¨¡å‹çš„åŸºæœ¬ä»»åŠ¡æ˜¯ï¼š<strong>æ ¹æ®å‰é¢çš„è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯</strong>ã€‚ç”¨Conditional Probabilityè¡¨ç¤ºï¼š</p>
<p><span class="math display">\[
P(w_5 \mid w_1, w_2, w_3, w_4)
\]</span></p>
<p>This expresses the probability of the 5th word given the first four.</p>
<section id="example" class="level4">
<h4 class="anchored" data-anchor-id="example">Example:</h4>
<p>Sentence: <em>â€œLuck is what happens when preparation meets opportunity.â€</em></p>
<p>åœ¨â€œLuck is what happensâ€ä¹‹åå‡ºç°â€œwhenâ€çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ</p>
</section>
</section>
<section id="chain-rule-of-probability" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule-of-probability">Chain Rule of Probability</h3>
<p>To compute complex conditional probabilities, we use the <strong>chain rule</strong>:</p>
<p>ä¸ºäº†è®¡ç®—å¤æ‚çš„æ¡ä»¶æ¦‚ç‡ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¦‚ç‡çš„Chain Ruleï¼š</p>
<ul>
<li>Basic rule: <span class="math inline">\(P(A \cap B) = P(A) P(B|A)\)</span></li>
<li>Conditional probability definition: <span class="math inline">\(P(B|A) = \frac{P(A \cap B)}{P(A)}\)</span></li>
<li>Generalized form: <span class="math inline">\(P(A \cap B \cap C) = P(C|B \cap A) P(B|A) P(A)\)</span></li>
</ul>
<p>In the context of language:</p>
<p>ç›®æ ‡æ˜¯ä¼°è®¡ï¼š</p>
<p><span class="math display">\[
P(\text{when} \mid \text{happens}, \text{what}, \text{is}, \text{luck})
\]</span></p>
<p>ä½¿ç”¨chain ruleå±•å¼€ï¼š</p>
<p><span class="math display">\[
P(\text{when}) = P(\text{when} \mid \text{happens} \cap \text{what} \cap \text{is} \cap \text{luck}) \\
\cdot P(\text{happens} \mid \text{what} \cap \text{is} \cap \text{luck}) \\
\cdot P(\text{what} \mid \text{is} \cap \text{luck}) \\
\cdot P(\text{is} \mid \text{luck}) \\
\cdot P(\text{luck})
\]</span></p>
<p>è¿™å°±æ˜¯è¯­è¨€æ¨¡å‹ä¸­å¸¸ç”¨çš„æ€è·¯ï¼šå°†ä¸€ä¸ªå¥å­ä¸­å„ä¸ªè¯çš„è”åˆæ¦‚ç‡è½¬åŒ–ä¸ºä¸€ç³»åˆ—æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ã€‚</p>
<hr>
</section>
</section>
<section id="perplexity-and-cross-entropy" class="level2">
<h2 class="anchored" data-anchor-id="perplexity-and-cross-entropy">Perplexity and Cross-Entropy</h2>
<section id="perplexity" class="level3">
<h3 class="anchored" data-anchor-id="perplexity">Perplexity</h3>
<p>Perplexity evaluates how well a probability model predicts a sample:</p>
<blockquote class="blockquote">
<p><strong>Perplexity = 2 raised to the cross-entropy of the model</strong></p>
</blockquote>
<p>Perplexityè¡¡é‡çš„æ˜¯æ¨¡å‹å¯¹æµ‹è¯•é›†çš„â€œå›°æƒ‘â€ç¨‹åº¦ï¼Œ<strong>è¶Šå°è¶Šå¥½</strong>ã€‚</p>
<p>å®ƒç­‰ä»·äºæ¨¡å‹æ¯é¢„æµ‹ä¸€ä¸ªè¯æ—¶çš„ä¸ç¡®å®šåº¦ã€‚</p>
<p><span class="math display">\[
\text{Perplexity} = 2^{-\frac{1}{W} \sum_{k=1}^{n} \log P(w_k)}
\]</span></p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(W\)</span>ï¼šæµ‹è¯•é›†ä¸­å•è¯æ€»æ•°</li>
<li><span class="math inline">\(P(w_k)\)</span>ï¼šæ¨¡å‹ç»™ç¬¬ <span class="math inline">\(k\)</span> ä¸ªè¯çš„æ¦‚ç‡é¢„æµ‹</li>
</ul>
</section>
<section id="cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy">Cross-Entropy</h3>
<p>Cross-entropy quantifies the average number of bits needed to encode data from a distribution <span class="math inline">\(\tilde{p}\)</span> using a model <span class="math inline">\(q\)</span>:</p>
<p>äº¤å‰ç†µï¼ˆCross-Entropyï¼‰ç”¨æ¥è¡¡é‡ä¸€ä¸ªåˆ†å¸ƒ <span class="math inline">\(\tilde{p}\)</span> å’Œæ¨¡å‹åˆ†å¸ƒ <span class="math inline">\(q\)</span> ä¹‹é—´çš„è·ç¦»ï¼š</p>
<p><span class="math display">\[
H(\tilde{p}, q) = -\sum_{i=1}^N \tilde{p}(x_i) \log_2 q(x_i)
\]</span></p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(\tilde{p}(x_i)\)</span>ï¼šç»éªŒæ¦‚ç‡ï¼ˆè¯ <span class="math inline">\(x_i\)</span> çš„å‡ºç°é¢‘ç‡ï¼‰</li>
<li><span class="math inline">\(q(x_i)\)</span>ï¼šæ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡</li>
</ul>
<p>å’Œ Perplexity çš„å…³ç³»ï¼š</p>
<p><span class="math display">\[
\text{Perplexity} = 2^{\text{Cross-Entropy}}
\]</span></p>
</section>
<section id="kl-divergence-relative-entropy" class="level3">
<h3 class="anchored" data-anchor-id="kl-divergence-relative-entropy">KL Divergence (Relative Entropy)</h3>
<p>KL æ•£åº¦è¡¡é‡ä¸€ä¸ªè¿‘ä¼¼åˆ†å¸ƒ <span class="math inline">\(q\)</span> ä¸çœŸå®åˆ†å¸ƒ <span class="math inline">\(p\)</span> çš„å·®å¼‚ã€‚å®ƒä¸å¯¹ç§°ï¼Œä½†å¦‚æœä¸¤è€…ç›¸ç­‰ï¼ŒKL æ•£åº¦ä¸º 0ã€‚</p>
<p>å…¬å¼ï¼š</p>
<p><span class="math display">\[
D_{KL}(p \parallel q) = \sum_{i=1}^N p(x_i) \log \left( \frac{p(x_i)}{q(x_i)} \right)
\]</span></p>
<ul>
<li><span class="math inline">\(p(x_i)\)</span>ï¼šçœŸå®åˆ†å¸ƒ</li>
<li><span class="math inline">\(q(x_i)\)</span>ï¼šæ¨¡å‹çš„è¿‘ä¼¼åˆ†å¸ƒ</li>
</ul>
<p>ç”¨é€”ï¼šKL æ•£åº¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¸¸ç”¨äºä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œæ¯”å¦‚é€šè¿‡æœ€å°åŒ– KL æ•£åº¦æ¥é€¼è¿‘çœŸå®åˆ†å¸ƒã€‚</p>
<hr>
</section>
</section>
<section id="text-representation-models" class="level2">
<h2 class="anchored" data-anchor-id="text-representation-models">Text Representation Models</h2>
<section id="bag-of-words-bow" class="level3">
<h3 class="anchored" data-anchor-id="bag-of-words-bow">Bag-of-Words (BoW)</h3>
<p>Converts text into vectors based on word occurrence counts.</p>
<p>BoWï¼ˆè¯è¢‹æ¨¡å‹ï¼‰å°†æ–‡æœ¬å‘é‡åŒ–ï¼Œæ¯ä¸ªç»´åº¦è¡¨ç¤ºè¯è¡¨ä¸­ä¸€ä¸ªè¯åœ¨å¥å­ä¸­å‡ºç°çš„é¢‘ç‡ã€‚</p>
<section id="ä¾‹å­è¯´æ˜" class="level4">
<h4 class="anchored" data-anchor-id="ä¾‹å­è¯´æ˜">ä¾‹å­è¯´æ˜ï¼š</h4>
<p>å¥å­ï¼š</p>
<pre><code>I WOULD NOT, COULD NOT IN THE RAIN.
NOT IN THE DARK. NOT ON A TRAIN.</code></pre>
<p>è¢«è½¬æ¢ä¸ºä¸¤ä¸ªå‘é‡ï¼š</p>
<pre><code>[1, 1, 1, 2, 1, 1, 1, 1, 0, 0, ..., 0]
[0, 0, 0, 2, 1, 1, 0, 1, 1, 1, ..., 0]</code></pre>
<p>æ¯ä¸ªæ•°è¡¨ç¤ºè¯è¡¨ä¸­å¯¹åº”å•è¯åœ¨è¯¥â€œæ–‡æ¡£â€ï¼ˆå³å¥å­ï¼‰ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚</p>
</section>
</section>
<section id="limitations-of-bow" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-bow">Limitations of BoW</h3>
<p>BoW çš„ä¸»è¦ç¼ºç‚¹ï¼š</p>
<ul>
<li><strong>ä¸è€ƒè™‘è¯­ä¹‰ï¼ˆSemantic meaningï¼‰</strong>ï¼šå¿½ç•¥ä¸Šä¸‹æ–‡ï¼Œæ¯”å¦‚â€œæˆ‘çˆ±ä½ â€å’Œâ€œä½ çˆ±æˆ‘â€ä¼šè¢«è§†ä¸ºç›¸åŒå‘é‡ã€‚</li>
<li><strong>ç»´åº¦é«˜ï¼ˆVector sizeï¼‰</strong>ï¼šè¯è¡¨å¤§æ—¶ï¼Œå‘é‡ç¨€ç–ã€å ç”¨èµ„æºå¤šã€‚</li>
</ul>
</section>
<section id="tf-idf-term-frequency-inverse-document-frequency" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf-term-frequency-inverse-document-frequency">TF-IDF (Term Frequency-Inverse Document Frequency)</h3>
<p>Gives less importance to common words:</p>
<p>ç›®çš„ï¼šé™ä½é«˜é¢‘æ— æ„ä¹‰è¯ï¼ˆå¦‚ â€œtheâ€, â€œandâ€ï¼‰çš„æƒé‡ï¼Œæé«˜æœ‰åŒºåˆ†åº¦çš„è¯çš„é‡è¦æ€§ã€‚</p>
<p>å®šä¹‰ï¼š</p>
<ul>
<li><strong>TFï¼ˆTerm Frequencyï¼‰</strong>ï¼šè¯åœ¨æ–‡æ¡£ä¸­çš„é¢‘ç‡ï¼›</li>
<li><strong>IDFï¼ˆInverse Document Frequencyï¼‰</strong>ï¼šè¯åœ¨æ•´ä¸ªæ–‡æ¡£é›†ä¸­å‡ºç°çš„â€œé€†é¢‘ç‡â€ã€‚</li>
</ul>
<p>å…¬å¼ï¼š</p>
<p><span class="math display">\[
\text{TF-IDF}(t, d) = tf(t, d) \cdot \log \left( \frac{N}{df(t)} \right)
\]</span></p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(t\)</span>ï¼šè¯</li>
<li><span class="math inline">\(d\)</span>ï¼šæ–‡æ¡£</li>
<li><span class="math inline">\(df(t)\)</span>ï¼šåŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°</li>
<li><span class="math inline">\(N\)</span>ï¼šæ–‡æ¡£æ€»æ•°</li>
</ul>
</section>
<section id="normalized-term-frequency" class="level3">
<h3 class="anchored" data-anchor-id="normalized-term-frequency">Normalized Term Frequency</h3>
<p>ä¸ºäº†è§£å†³æ–‡æ¡£é•¿çŸ­å¯¹è¯é¢‘å¸¦æ¥çš„åå·®ï¼Œå¯ä»¥è¿›è¡Œè§„èŒƒåŒ–å¤„ç†ï¼š</p>
<ul>
<li><p><strong>å¯¹æ•°ç¼©æ”¾ï¼ˆLog Normalizationï¼‰</strong>ï¼š <span class="math inline">\(\log(1 + f_{t,d})\)</span></p></li>
<li><p><strong>æœ€å¤§å€¼å½’ä¸€åŒ–ï¼ˆMax Normalizationï¼‰</strong>ï¼š</p>
<p><span class="math display">\[
tf(t,d) = 0.5 + 0.5 \cdot \frac{f_{t,d}}{\max \{f_{t',d} : t' \in d\}}
\]</span></p></li>
</ul>
<hr>
</section>
</section>
<section id="n-gram-models" class="level2">
<h2 class="anchored" data-anchor-id="n-gram-models">N-gram Models</h2>
<section id="bi-grams-and-n-grams" class="level3">
<h3 class="anchored" data-anchor-id="bi-grams-and-n-grams">Bi-grams and N-grams</h3>
<p>Bi-gramï¼ˆåŒè¯æ¨¡å‹ï¼‰è§£å†³ BoW å¿½ç•¥è¯åºçš„é—®é¢˜ï¼Œå°†æ¯ä¸¤ä¸ªè¯ä½œä¸ºä¸€ä¸ªå•å…ƒè¿›è¡Œå»ºæ¨¡ã€‚</p>
<p>ä¾‹å¦‚ï¼š</p>
<pre><code>"Luck is", "is what", "what happens", ...</code></pre>
</section>
<section id="n-gram-ä¸€èˆ¬åŒ–" class="level3">
<h3 class="anchored" data-anchor-id="n-gram-ä¸€èˆ¬åŒ–">N-gram ä¸€èˆ¬åŒ–</h3>
<p>N-gram æ˜¯å¯¹ Bi-gram çš„æ‹“å±•ï¼Œä½¿ç”¨å‰ <span class="math inline">\(N-1\)</span> ä¸ªè¯é¢„æµ‹å½“å‰è¯ã€‚</p>
<section id="æ•°å­¦è¡¨è¾¾å¼" class="level4">
<h4 class="anchored" data-anchor-id="æ•°å­¦è¡¨è¾¾å¼">æ•°å­¦è¡¨è¾¾å¼ï¼š</h4>
<ul>
<li>Unigram: <span class="math inline">\(P(w_i) = \frac{\text{Count}(w_i)}{\sum_j \text{Count}(w_j)}\)</span></li>
<li>Bigram: <span class="math inline">\(P(w_i | w_{i-1}) = \frac{\text{Count}(w_{i-1}, w_i)}{\text{Count}(w_{i-1})}\)</span></li>
<li>N-gram: <span class="math inline">\(P(w_1^n) = \prod_{k=1}^{n} P(w_k | w_{k-1})\)</span></li>
</ul>
<p>è¡¨ç¤ºæ•´å¥è¯çš„æ¦‚ç‡æ˜¯å„ä¸ªè¯çš„æ¡ä»¶æ¦‚ç‡è¿ä¹˜ã€‚</p>
</section>
</section>
<section id="out-of-vocabulary-wordsè¯è¡¨å¤–è¯" class="level3">
<h3 class="anchored" data-anchor-id="out-of-vocabulary-wordsè¯è¡¨å¤–è¯">Out-of-Vocabulary Wordsï¼ˆè¯è¡¨å¤–è¯ï¼‰</h3>
<p>å½“è®­ç»ƒé›†ä¸­æ²¡æœ‰å‡ºç°çš„è¯å« OOVï¼ˆOut-of-Vocabularyï¼‰ï¼Œè¿™ä¼šå¯¼è‡´æ¦‚ç‡ä¸ºé›¶ã€‚</p>
<p>è§£å†³åŠæ³•ï¼š</p>
<ul>
<li><p>æ‰©å¤§è¯­æ–™åº“ï¼ˆIncrease corpus sizeï¼‰</p></li>
<li><p>è·³è¿‡ç¼ºå¤±çš„ n-gramï¼ˆLeap over missing n-gramsï¼‰</p></li>
<li><p>ä½¿ç”¨å¹³æ»‘æŠ€æœ¯ï¼ˆSmoothingï¼‰ï¼Œå¦‚ï¼š <span class="math inline">\(P_{\text{Laplace}}(w_i) = \frac{c_i + 1}{N + V}\)</span> å…¶ä¸­ï¼š</p>
<ul>
<li><span class="math inline">\(c_i\)</span>ï¼šè¯ <span class="math inline">\(w_i\)</span> å‡ºç°æ¬¡æ•°</li>
<li><span class="math inline">\(N\)</span>ï¼šè¯æ€»æ•°</li>
<li><span class="math inline">\(V\)</span>ï¼šè¯è¡¨å¤§å°</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="sentiment-analysis-and-semantic-orientation" class="level2">
<h2 class="anchored" data-anchor-id="sentiment-analysis-and-semantic-orientation">Sentiment Analysis and Semantic Orientation</h2>
<section id="definition" class="level3">
<h3 class="anchored" data-anchor-id="definition">Definition</h3>
<p>Semantic orientation analyzes sentiment strength and direction in text.</p>
<p>è¯­ä¹‰å€¾å‘ï¼ˆSemantic Orientationï¼‰ç”¨äºåˆ¤æ–­æ–‡æœ¬ä¸­å•è¯æˆ–çŸ­è¯­çš„æƒ…ç»ªææ€§å’Œå¼ºåº¦ã€‚</p>
<section id="key-dimensions" class="level4">
<h4 class="anchored" data-anchor-id="key-dimensions">Key dimensions:</h4>
<ul>
<li><strong>Subjectivity</strong>: objective vs subjective ï¼ˆå®¢è§‚ vs ä¸»è§‚ï¼‰</li>
<li><strong>Polarity</strong>: negative vs positive ï¼ˆè´Ÿé¢ vs æ­£é¢ï¼‰</li>
<li><strong>Intensity</strong>: strength (e.g.&nbsp;â€œvery goodâ€ vs â€œgoodâ€)</li>
</ul>
</section>
</section>
<section id="lexicon-based-approach" class="level3">
<h3 class="anchored" data-anchor-id="lexicon-based-approach">Lexicon-Based Approach</h3>
<p>åŸºäºäººå·¥æˆ–åŠè‡ªåŠ¨æ„å»ºçš„æƒ…æ„Ÿè¯å…¸ï¼Œå¦‚ Hu &amp; Liuï¼ˆ2004ï¼‰çš„æ–¹æ³•ï¼š</p>
<ul>
<li>æå– <strong>æ„è§è¯ï¼ˆopinion wordsï¼‰</strong>ï¼Œå¦‚å½¢å®¹è¯ï¼ˆgood, bad, amazingï¼‰ï¼›</li>
<li>ä½¿ç”¨ WordNet è·å–åŒä¹‰è¯/åä¹‰è¯ï¼Œæ¨æ–­å…¶æƒ…ç»ªå€¾å‘ï¼›</li>
<li>é€è¯åˆ†æå¹¶åˆå¹¶ä¸ºå¥å­çº§åˆ«åˆ¤æ–­ã€‚</li>
</ul>
</section>
<section id="wordnet-role" class="level3">
<h3 class="anchored" data-anchor-id="wordnet-role">WordNet Role</h3>
<p>WordNet æ˜¯ä¸€ä¸ªè¯æ±‡çŸ¥è¯†åº“ï¼Œå®ƒç”¨è¯­ä¹‰å…³ç³»è¿æ¥å•è¯ï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li>Synonymï¼ˆåŒä¹‰è¯ï¼‰ï¼šå½¢æˆåŒä¹‰é›† Synsets</li>
<li>Antonymï¼ˆåä¹‰è¯ï¼‰ï¼šå¦‚ wet ä¸ dry</li>
<li>ä¸Šä¸‹ä½å…³ç³»ï¼ˆHypernym-Hyponymï¼‰ï¼šå¦‚ furniture &gt; bed</li>
<li>éƒ¨åˆ†æ•´ä½“å…³ç³»ï¼ˆMeronymï¼‰ï¼šå¦‚ chair ä¸ backrest</li>
</ul>
</section>
<section id="limitations-of-lexicon-methods" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-lexicon-methods">Limitations of Lexicon Methods</h3>
<p>å¼•ç”¨è‡ª Agarwal &amp; Mittalï¼ˆ2015ï¼‰ï¼š</p>
<p>ä¸»è¦é—®é¢˜ï¼š</p>
<ul>
<li>ä¾èµ–è®­ç»ƒè¯­æ–™åº“ä¸­çš„å·²æœ‰è¯æ±‡ï¼›</li>
<li>å¯¹æ–°è¯ã€ä¿šè¯­ã€ç‰¹å®šé¢†åŸŸæœ¯è¯­æ— èƒ½ä¸ºåŠ›ï¼›</li>
<li>è‹¥è¯å…¸è¦†ç›–ä¸å…¨ï¼Œç³»ç»Ÿå®¹æ˜“å¤±è¯¯ï¼›</li>
<li>æ–‡æœ¬é•¿åº¦è¶ŠçŸ­ï¼Œè¯­ä¹‰è¶Šéš¾åˆ¤æ–­å‡†ç¡®ã€‚</li>
</ul>
<hr>
</section>
</section>
<section id="summary-table" class="level2">
<h2 class="anchored" data-anchor-id="summary-table">Summary Table</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 39%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Topic</th>
<th>Key Concept</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Language Modeling</td>
<td>Predict next word</td>
<td>Sensitive to data sparsity</td>
</tr>
<tr class="even">
<td>Perplexity</td>
<td>Measures modelâ€™s confusion</td>
<td>Lower = better</td>
</tr>
<tr class="odd">
<td>BoW</td>
<td>Simple vector representation</td>
<td>Ignores word order</td>
</tr>
<tr class="even">
<td>TF-IDF</td>
<td>Penalizes common words</td>
<td>Still context-free</td>
</tr>
<tr class="odd">
<td>N-gram</td>
<td>Uses local context</td>
<td>Struggles with OOV words</td>
</tr>
<tr class="even">
<td>Lexicon Sentiment</td>
<td>Dictionary-based polarity</td>
<td>Poor generalization</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="what-are-topic-models" class="level2">
<h2 class="anchored" data-anchor-id="what-are-topic-models">What Are Topic Models?</h2>
<p>Topic models are statistical methods that discover abstract â€œtopicsâ€ in a collection of documents. The most well-known model is <strong>Latent Dirichlet Allocation (LDA)</strong>. Documents are modeled as mixtures of topics, and each topic is characterized by a distribution over words.</p>
<p>æ˜¯ä¸€ç±»æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿä»æ–‡æœ¬é›†åˆä¸­è‡ªåŠ¨å‘ç°<strong>æ½œåœ¨è¯é¢˜</strong>ã€‚</p>
<ul>
<li>doc = å¤šä¸ªä¸»é¢˜çš„æ··åˆï¼›</li>
<li>topic = ä¸€ç»„è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
</ul>
<hr>
</section>
<section id="lda-graphical-structure-plate-notation" class="level2">
<h2 class="anchored" data-anchor-id="lda-graphical-structure-plate-notation">LDA Graphical Structure &amp; Plate Notation</h2>
<ul>
<li>Î±ï¼šæ§åˆ¶æ–‡æ¡£ä¸­ä¸»é¢˜åˆ†å¸ƒçš„ Dirichlet å…ˆéªŒ</li>
<li>Î¸_dï¼šç¬¬ d ç¯‡æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒ</li>
<li>z_dnï¼šç¬¬ d ç¯‡æ–‡æ¡£ä¸­ç¬¬ n ä¸ªè¯çš„ä¸»é¢˜</li>
<li>Î²_kï¼šç¬¬ k ä¸ªä¸»é¢˜ä¸‹çš„è¯åˆ†å¸ƒ</li>
<li>w_dnï¼šå®é™…ç”Ÿæˆçš„è¯</li>
<li>Î·ï¼šæ§åˆ¶ Î² çš„ Dirichlet è¶…å‚æ•°</li>
</ul>
<p>ğŸ§¾ <strong>ç”Ÿæˆè¿‡ç¨‹</strong>ï¼š</p>
<ol type="1">
<li>å¯¹æ¯ç¯‡æ–‡æ¡£ dï¼Œä» Dirichlet(Î±) æŠ½æ ·å‡º Î¸_d</li>
<li>å¯¹æ¯ä¸ªè¯ï¼Œä» Multinomial(Î¸_d) é€‰æ‹©ä¸»é¢˜ z_dn</li>
<li>å†ä» Multinomial(Î²_{z_dn}) ä¸­é‡‡æ ·å‡ºè¯ w_dn</li>
</ol>
<hr>
</section>
<section id="lda-as-soft-clustering" class="level2">
<h2 class="anchored" data-anchor-id="lda-as-soft-clustering">LDA as Soft Clustering</h2>
<p>LDA æ˜¯ä¸€ç§Soft Clusteringï¼‰ * Each word is probabilistically assigned to a topic. * Unlike hard clustering (e.g.&nbsp;K-means), LDA allows multiple topics per document.</p>
<ul>
<li>æ¯ä¸ªè¯æ˜¯ä»å¤šä¸ªä¸»é¢˜ä¸­ä»¥æ¦‚ç‡æ–¹å¼æŠ½æ ·å¾—åˆ°çš„ï¼›</li>
<li>æ¯ä¸ªæ–‡æ¡£å¯èƒ½å±äºå¤šä¸ªä¸»é¢˜ï¼›</li>
<li>åŒºåˆ«äº Latent Class æ¨¡å‹ï¼ˆç¡¬èšç±»ï¼Œæ¯ä¸ªæ–‡æ¡£åªå±äºä¸€ä¸ªä¸»é¢˜ï¼‰ã€‚</li>
</ul>
<hr>
</section>
<section id="lda-as-dimension-reduction" class="level2">
<h2 class="anchored" data-anchor-id="lda-as-dimension-reduction">LDA as Dimension Reduction</h2>
<p>LDA ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§<strong>é™ç»´æŠ€æœ¯</strong>ï¼š * æŠŠé«˜ç»´çš„è¯é¢‘å‘é‡æ˜ å°„ä¸ºä½ç»´çš„ä¸»é¢˜ç©ºé—´ï¼› * ä¸ PCA ç±»ä¼¼ï¼Œä½†ï¼š * LDA çš„åˆ†é‡æ˜¯æ­£æ•° * ç”¨æ¦‚ç‡å»ºæ¨¡è€Œéçº¿æ€§æŠ•å½±</p>
<p>ğŸ“Œ æ›¿ä»£æ–¹æ¡ˆï¼šçŸ©é˜µåˆ†è§£ï¼ˆMatrix Factorizationï¼‰ã€äº¤æ›¿æœ€å°äºŒä¹˜ï¼ˆALSï¼‰ * Expected word vector: <span class="math inline">\(\mathbb{E}[w] = \theta^\top \beta\)</span> * Î¸: documentâ€™s topic distribution * Î²: topicâ€™s word distribution</p>
<hr>
</section>
<section id="variational-inference-in-lda" class="level2">
<h2 class="anchored" data-anchor-id="variational-inference-in-lda">Variational Inference in LDA</h2>
<p><strong>Why Variational Inference (VI)?</strong></p>
<ul>
<li>Posterior <span class="math inline">\(p(\theta, z \mid w)\)</span> is intractable.</li>
<li>VI approximates it with simpler <span class="math inline">\(q(\theta, z)\)</span> by minimizing KL divergence.</li>
</ul>
<p><strong>VI Mechanism:</strong></p>
<ul>
<li><p>Use mean-field factorization: <span class="math inline">\(q(\theta, z) = q(\theta) \prod_n q(z_n)\)</span></p></li>
<li><p>Optimize parameters <span class="math inline">\(\gamma, \phi\)</span></p></li>
<li><p>Iteratively update:</p>
<ul>
<li><span class="math inline">\(\phi_{ni} \propto \beta_{i w_n} \exp(\Psi(\gamma_i))\)</span></li>
<li><span class="math inline">\(\gamma_i = \alpha_i + \sum_n \phi_{ni}\)</span></li>
</ul></li>
<li><p>è´å¶æ–¯æ¨æ–­è¦æ±‚è®¡ç®—åéªŒåˆ†å¸ƒï¼Œä½†ä¸å¯è§£æï¼›</p></li>
<li><p>VI æŠŠæ¨æ–­é—®é¢˜è½¬ä¸ºä¼˜åŒ–é—®é¢˜ï¼š</p>
<ul>
<li>é€‰ä¸€ä¸ªå¯å¤„ç†çš„åˆ†å¸ƒæ— <span class="math inline">\(q\)</span>ï¼Œä½¿å…¶æœ€æ¥è¿‘çœŸå®åéªŒã€‚</li>
<li>ç”¨å˜åˆ†å‚æ•° <span class="math inline">\(\gamma\)</span> å’Œ <span class="math inline">\(\phi\)</span> è¡¨è¾¾æ–‡æ¡£çš„ä¸»é¢˜è¡¨ç¤ºå’Œè¯çš„ä¸»é¢˜åˆ†å¸ƒã€‚</li>
</ul></li>
</ul>
<p><strong>æ¯”è¾ƒï¼š</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>æ–¹æ³•</th>
<th>ä¼˜ç‚¹</th>
<th>ç¼ºç‚¹</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MCMC</td>
<td>ç²¾åº¦é«˜</td>
<td>æ…¢ï¼Œä¸é€‚åˆå¤§è§„æ¨¡</td>
</tr>
<tr class="even">
<td>VI</td>
<td>å¿«ï¼Œæœ‰è§£æå½¢å¼</td>
<td>æœ‰åå·®ï¼Œä¾èµ–åˆ†å¸ƒæ—</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="extensions-of-lda" class="level2">
<h2 class="anchored" data-anchor-id="extensions-of-lda">Extensions of LDA</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>æ‰©å±•æ¨¡å‹</th>
<th>æè¿°</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CTMï¼ˆCorrelated Topic Modelï¼‰</td>
<td>ä½¿ç”¨ Logistic Normal å»ºæ¨¡ä¸»é¢˜ç›¸å…³æ€§</td>
</tr>
<tr class="even">
<td>Author-Topic Model</td>
<td>æ¯ä¸ªä½œè€…æ‹¥æœ‰ä¸€ä¸ªä¸»é¢˜åˆ†å¸ƒ</td>
</tr>
<tr class="odd">
<td>Dynamic Topic Model</td>
<td>æ¨¡å‹ä¸­ä¸»é¢˜ä¼šéšæ—¶é—´å˜åŒ–</td>
</tr>
</tbody>
</table>
<p>ğŸ“Œ ç¼ºç‚¹ï¼šè¿™äº›æ‰©å±•å¾€å¾€ç ´å Dirichlet çš„ç®€æ´æ€§è´¨ï¼Œä½¿å¾—æ¨æ–­å˜å¾—æ›´å¤æ‚ï¼ˆé€šå¸¸éœ€è¦ MCMC æˆ– EPï¼‰</p>
<hr>
</section>
<section id="sentence-constrained-lda" class="level2">
<h2 class="anchored" data-anchor-id="sentence-constrained-lda">Sentence-Constrained LDA</h2>
<p>SC-LDA å‡è®¾ï¼š<strong>ä¸€å¥è¯é€šå¸¸åªè®²ä¸€ä¸ªä¸»é¢˜</strong>ï¼Œå¹¶ä¸”è¿™ä¸ªä¸»é¢˜å¯èƒ½åœ¨ä¸‹ä¸€å¥ä¸­å»¶ç»­ã€‚</p>
<ul>
<li>æ¯å¥ â†’ ä¸€ä¸ªä¸»é¢˜</li>
<li>æ›´è´´è¿‘ç”¨æˆ·åœ¨è¯„è®ºä¸­çš„è¡¨è¾¾ç»“æ„</li>
<li>å¯ç”¨äºäº§å“å±æ€§æå–ï¼ˆå¦‚â€œå±å¹•ã€ä»·æ ¼ã€ç”µæ± â€ï¼‰</li>
<li>æ–‡æ¡£çš„ä¸»é¢˜åˆ†å¸ƒå¯ç”¨äº<strong>é¢„æµ‹è¯„åˆ†</strong></li>
<li>Each sentence tends to express one topic (Buschken &amp; Allenby, 2016)</li>
<li>Better topic-word tail modeling</li>
<li>Improves interpretability &amp; rating prediction</li>
</ul>
<section id="æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜" class="level3">
<h3 class="anchored" data-anchor-id="æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜">æƒ…æ„Ÿä¸æ˜¯ä¸»é¢˜ï¼š</h3>
<ul>
<li>ä¸»é¢˜ç”±â€œåè¯â€é©±åŠ¨ï¼Œæƒ…æ„Ÿç”±â€œå½¢å®¹è¯â€é©±åŠ¨ï¼›</li>
<li>åŒä¸€ä¸ªä¸»é¢˜å¯èƒ½åŒ…å«è¤’è´¬ä¸ä¸€çš„å†…å®¹ï¼›</li>
<li>åœ¨å¤§æ•°æ®ä¸­å¯èƒ½å­¦å‡ºâ€œä¸»é¢˜+æƒ…ç»ªâ€å¤åˆç»“æ„ï¼ˆå¦‚â€œbad batteryâ€ï¼‰</li>
</ul>
<p>Topic Ã— Sentiment:</p>
<ol type="1">
<li>å…ˆè¯†åˆ«å¥å­çš„ä¸»é¢˜ï¼ˆSC-LDAï¼‰</li>
<li>å¯¹å¥å­åšæƒ…ç»ªåˆ†ç±»</li>
<li>å°†æƒ…ç»ªä¸ä¸»é¢˜è¿›è¡Œäº¤äº’å»ºæ¨¡ â†’ æ–¹é¢çº§æƒ…æ„Ÿåˆ†æï¼ˆAspect-Based Sentiment Analysisï¼‰</li>
</ol>
<hr>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>ä¸»é¢˜</th>
<th>å†…å®¹</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LDA æ ¸å¿ƒ</td>
<td>ä¸»é¢˜åˆ†å¸ƒ Ã— è¯åˆ†å¸ƒï¼ˆÎ¸ Ã— Î²ï¼‰</td>
</tr>
<tr class="even">
<td>æ¨æ–­æ–¹æ³•</td>
<td>VIï¼ˆå¿«ï¼‰ vs MCMCï¼ˆå‡†ï¼‰</td>
</tr>
<tr class="odd">
<td>æ¨¡å‹ç»“æ„</td>
<td>æ–‡æ¡£ = å¤šä¸»é¢˜ï¼Œè¯ = ä»ä¸»é¢˜ä¸­æŠ½æ ·</td>
</tr>
<tr class="even">
<td>å˜ä½“</td>
<td>CTM, Dynamic LDA, Author-Topic, SC-LDA</td>
</tr>
<tr class="odd">
<td>è¿›é˜¶æ–¹å‘</td>
<td>åŠ å…¥æƒ…ç»ªã€æ—¶é—´ã€ç»“æ„åŒ–å…ˆéªŒ</td>
</tr>
</tbody>
</table>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>Hu, M., &amp; Liu, B. (2004). Mining and summarizing customer reviews.</li>
<li>Agarwal, A., &amp; Mittal, N. (2015). Text classification using machine learning methods.</li>
<li>WordNet: <a href="https://wordnet.princeton.edu/">https://wordnet.princeton.edu/</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>